# Introduction

HTTP/2, is a major revision of the HTTP network protocol meant to improve the
perceived performance of loading web content.

## HTTP/1.1

This protocol has lived on for over 20 years. It fixed a number of problems
found in the 1.0 version. By making the Host header mandatory, it was now
possible to perform virtual hosting, or serving multiple web properties on a
single IP address.

When the new connection directives are used, a web server is not required to close
a connection after a response. This was a boon for performance and efficacy since
the browser no longer needed to reestablish the TCP connection on every request.

Additional changes included:

  - An extension of cacheability headers
  - An OPTIONS method
  - The Upgrade header
  - Range requests
  - Compression with transfer-encoding
  - Pipelining

=> Pipelining is a feature that allows a client to send all of its requests
at once. There were a couple of problems with pipelining that prevented its
popularity. Servers still had to respond to the requests in order. This meant
if one request takes a long time, this head of line blocking will get in the
way of the other requests.

## SPDY

An alternative to HTTP which laid the groundwork for HTTP/2 and was responsible
for proviing out some of its key features such as multiplexing, framing, and header
compression, among others. It was integrated quickly to Chrome and Firefox, and
eventually would be adopted by almost every major browser.

## HTTP/2

Expectations for HTTP/2:
  - Substantially and measurably improve end-user perceived latency in most cases,
  over HTTP/1.1 using TCP

  - Address the "head of line blocking" problem in HTTP.  

  - Not require multiple connections to a server to enable parallelims, thus
  improving its use of TCP, espcially regarding congestion control.

  - Retain the semantics of HTTP/1.1, leveraging existing documentation
  including HTTP methods, status, codes, URIs, and header fields.

  - Clearly define how HTTP/2.0 interacts with HTTP/1.x, especially in
  intermediaries (both 2->1 and 1->2)

  - Clearly identify any new extensibility points and policy for their appropriate use.


## HTTP2/ Quick start

### Performance Challenges today

Delivering a modern web page or web application is far from trivial affair.
With hundreds of objects per page, tens of domains, variability in the
networks, and a wide range of device abilities, creating a consistent and
fast web experience is a challenge.

#### The Anatomy of a Web page request

When a web browser requests a web page, it goes through a repetitive process to
get all of the information it needs to paint the page on the screen. It is easisest
to think of this in two parts: the object fetching logic, and the page parsing/rendering
logic.

=> Put Web page in Fetch Queue => URL in fetch queue => Resolve Host name (DNS) => Open TCP connection
=> Perform TLS handshake if HTTPs => Send request

1. Put the URL to the fetch queues
2. Resolve the IP address of the hostname in the URL
3. Open a TCP connection to the host  
4. If it is an HTTPS request, initiate and finish a TLS handshake
5. Send the request for the base page URL
6. Receive the response
7. I this is the base HTML, parse it and trigger prioritiese fetches for the objects
on the page
8. If the critical objects on a page have been recieved, continue to parse and render
until done.

##### Critical Performance

=> Latency: The latency is how long it takes for an IP packet to get from one
point to another. Related is the round-trip Time (RTT), which is twice the latency.
Latency is a major bottleneck to performance, especially for protocols such as
HTTP, which tend to make many round-trips to the server.

=> Bandwidth: A connection between two points can only handle so much data at one
time before it is saturated. Depending on the amount of data on a webpage and
the capacity of the connection, bandwidth may be a bottleneck to performance.

=> DNS lookup: Before a client can fetch a web pae, it needs to translate the hostname
to an IP address using the Domain Name System (DNS), the internet's phone book.
This needs to happen for every unique hostname on the fetched HTML page as well,

=> Conneciton time: Establishing a connection requires a back and forth (round-trip)
between the client and the server called the "three-way handshake". This handshake time
is generally related to the latency between the client and the server. The handshake
involves sending a synchronize (SYN) packet from the client to the server, followed
by an acknowlegement (ACK) of that SYN from the server, a SYN packet from the server
to the client, and an ACK of that SYN from the client to the server.

=> TLS negotiation time: If the client is making an HTTPS connection, it needs to negotiate
transport layer security (TLS), the successor to Secure sOCKET layer (SSL). This involves
more round trips on top of the server and client processing time.

### Problems with HTTP/1

=> Head of line blocking: A browser rarely wants to et a single object from a perticular
host. More often it wants get many objects at the same time. HTTP/1 provides no
mechanism to ask for those object simultaneously.
On a single connection it needs to send a request and then wait for a reponse before
it can send another.

H1 has a feature called pipelining that allows it to send a bunch of requests at once.
but it will still receive the responses one after the other in the order they were
sent.

==> Inefficient use of TCP: TCP was designed to be conservative in its assumptions and fair
to the different traffic uses on a network. Its congestion avoidance mechanisms are built
to work on the poorest of networks and be relatively fair in the presence of competing demand.

  - The congestion windo: It's the number of TCP packets that the sender can transmit
  out before beign acknowledged by the receiver.

  - A packet : an IP packet is a series of bytes (payload) encapsulated in a structure (frame)
  that defines how long the packet is, how it should be delivered (where it came from and where
    its going), and other items needed to speak TCP. The most data we can effectively put
    in a packet's payload is 1460 bytes.

## Summary

HTTP/1.1 has bred a messy if not exciting world of performance optimizations and best
practices. The contortions that the industry has gone through to eek out peformance
have been extraordinary. One of the goals of HTTP/2 is to make many of these techniques
obsolete.
