# Design Consistent Hashing 

To achieve horizontal scaling, it is important to distributed requests/data efficiently and evenly 
accross servers. Consistent hashing is a commonly used technque to achieve this goal.

## The rehashing problem 

If you have n cache servers, a common way to balance the load is to use the following hash method 

```python 

serverIndex = hash(key)%N // where N is the size of the server pool 

``` 

To fetch the server where a key is stored, we perform the modular operation f(key)%4. For instance 
hash(key0) % 4 = 1 means a client must contact server 1 to fetch the cached data.

This approach to hashing has some drawbacks, most keys are redistributecd, not just the ones originally stored 
in the offline server (cfr book). If one server goes offline, most cache clients will connect to the wrong 
servers to fetch data. This causes a storm of cache misses. consistent hashing is an effective technique 
to mitigate this problem. 

## COnsistent hashing 

Consistent hashing is a special kind of hashing such that when a hash table is resized and consistent hashing is 
used, only k/n keys need to be remapped on average. where k is the number of keys, and n is the number of slots.
In contrast, in most traditional hash tables, a change in the number of arrays slots causes nearly all keys 
to be remapped.

### Hash space and hash ring 

Assume SHA-1 i used as the hash function f, and the output range of the hash function is : x0, x1, x2, x3, ..., xn 
In cryptography, SHA-1's hash space goes from 0 to 2^160-1. That means x0 corresponds to 0, xN corresponds 
to 2^160 - 1, and all the other hash values in the middle fall between 0 and 2^160-1. 

By connecting both ends, we get a hash ring that goes from x0 to xN

### Hash servers 

Using the same hash function f, we map servers based on server IP or name onto the ring. 


### Hash Keys 

One thing worth mentioning is that hash funcon used here is different from the one in "the rehashing problem" 
and there is no modular operation. As shown in Figure 5-6, 4 cache keys (key0, key1, key2 and key3) are 
hashed onto the hash ring.

### Server lookup 

To determine which server a keys is stored on, we go clockwise from the key position on the ring until a server 
is found.

### Add a server 

Using the logic describe above, adding a new server will only require redistribution of a function of keys. 
In figure 5-8, after a new

### Remove a server 

When a server is removed, only a small fraction of keys require redistribution with consistent hashing.


## Two issues with the basic approach 

The basics steps of consistent hashing involve: 
	- Map servers and keys on to the ring using a uniformly distributed hash function 
	- To find out which server a key is mapped to, go clockwise from the key position until the first server on the 
	ring is found. 

Two problems are identified with this approach, first it is impossible to keep the same size of partitions 
on the ring for all servers considering a server can be added or removed. A partition is the hash space between 
adjacent servers. It is possible that the size of the partition on the ring assigned to each server is very 
small or fairly large.

Second, it is possible to have a non-uniform key distribution on the ring. 
A technique called virtual nodes or replicas is used to solve these problems. 

### Virtual nodes 

A virtual node refers to the real node, and ach server is represented by multiple virtual nodes on the ring. 
With virtual nodes, each server is responsible for multiple partitions. Partitions (edges) with label s0 are 
managed by server 0. On the other hand, partitions with label s1 are managed by server 1.

To find which server a key is stored on, we go clockwise from the key's location and find the first virtual 
node encountered on the ring. In figure 5-13, to find out which server k0 is stored on, we go clockwise 
from k0's location and find virtual nodes s1_1, which refers to server 1


As the number of virtual nodes iincreases, the distribution of keys becomes more balanced. 
This is because the standard deviation gets smaller with more virtual nodes, leading to 
balanced data distribution. Standard deviation measures how data are spread out.


## Wrap Up 

The benefits of consistent hasing include: 
	- Minimized keys are redistributed when servers are added or removed. 
	- It is easy to scale horizontally because data are more evenly distributed 
	- Mitigate hotspot key problem. Excessive access to a specific shard could cause server overload. 

Consistent hashing is widely used in real-world systems, including some notable ones: 

	- Partitioning component of Amazon's Dynamo database 
	- Data partitioning across the cluster in Apache Cassandra 
	- Discord chat application 
	- Akamai content delivery networK

